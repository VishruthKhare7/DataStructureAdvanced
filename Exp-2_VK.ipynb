{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Data Preprocessing like outlier detection, handling missing value, analyzing redundancy and normalization on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All machine learning algorithms use some input data to create outputs. This input data comprise features, which are usually in the form of structured columns. Algorithms require features with some specific characteristic to work properly.\n",
    "•\tPreparing the proper input dataset, compatible with the machine learning algorithm requirements.\n",
    "\n",
    "•\tImproving the performance of machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is considered as one of the most popular machine learning library in Python.Array interface is the best and the most important feature of Numpy. \n",
    "\n",
    "Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. \n",
    "Pandas is a machine learning library in Python that provides data structures of high-level and a wide variety of tools for analysis. One of the great feature of this library is the ability to translate complex operations with data using one or two commands. \n",
    "\n",
    "Scikit Learn is a Python library is associated with NumPy and SciPy. It is considered as one of the best libraries for working with complex data. \n",
    "\n",
    "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names) \n",
    "df['target'] = diabetes.target\n",
    "df.head()\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. _diabetes_dataset:\n",
    "Ten baseline variables, age, sex, body mass index, average blood\n",
    "pressure, and six blood serum measurements were obtained for each of n =\n",
    "442 diabetes patients, as well as the response of interest, a\n",
    "quantitative measure of disease progression one year after baseline.\n",
    "**Data Set Characteristics:**\n",
    "  :Number of Instances: 442\n",
    "  :Number of Attributes: First 10 columns are numeric predictive values\n",
    "  :Target: Column 11 is a quantitative measure of disease progression one year\n",
    "after baseline\n",
    "  :Attribute Information:\n",
    "- age\n",
    "- sex\n",
    "- bmi\n",
    "- bp\n",
    "- s1\n",
    "- s2\n",
    "- s3\n",
    "- s4\n",
    "- s5\n",
    "- s6\n",
    "age in years\n",
    "body mass index\n",
    "average blood pressure\n",
    "tc, T-Cells (a type of white blood cells)\n",
    "ldl, low-density lipoproteins\n",
    "hdl, high-density lipoproteins\n",
    "tch, thyroid stimulating hormone\n",
    "ltg, lamotrigine\n",
    "glu, blood sugar level\n",
    "Note: Each of these 10 feature variables have been mean centered and scaled by\n",
    "the standard deviation times `n_samples` (i.e. the sum of squares of each colum\n",
    "n totals 1).\n",
    "Source URL:\n",
    "\n",
    "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html \n",
    "\n",
    "(https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html)\n",
    "\n",
    "For more information see:\n",
    "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
    "\n",
    "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"The features of the dataset are\" ,diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features of the dataset are ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3','s4', 's5', 's6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation fills in the missing value with some number. The imputed value won't be exactly right in most cases, but it usually gives more accurate models than dropping the column entirely. The default behavior fills in the mean value for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan , strategy = 'mean') \n",
    "X = df.iloc[:,:-1].values\n",
    "y= df.iloc[:,-1].values\n",
    "imputer.fit(X[:,:])\n",
    "#Inserting missing values manually\n",
    "X[0][0]=np.nan X[2][1]=np.nan\n",
    "#Dataset with missing values\n",
    "print(\"Dataset with missing values\") \n",
    "print(pd.DataFrame(X,columns=diabetes.feature_names).head()) \n",
    "print()\n",
    "#Dataset without missing values\n",
    "X[:,:] = imputer.transform(X[:,:])\n",
    "print(\"Dataset WITHOUT missing values\") \n",
    "print(pd.DataFrame(X,columns=diabetes.feature_names).head()) \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset with missing values\n",
    "age sex bmi bp s1 s2 s3\\\n",
    "0       NaN  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401\n",
    "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412\n",
    "2  0.085299       NaN  0.044451 -0.005671 -0.045599 -0.034194 -0.032356\n",
    "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038\n",
    "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142\n",
    "         s4        s5        s6\n",
    "0 -0.002592  0.019908 -0.017646\n",
    "1 -0.039493 -0.068330 -0.092204\n",
    "2 -0.002592  0.002864 -0.025930\n",
    "3  0.034309  0.022692 -0.009362\n",
    "4 -0.002592 -0.031991 -0.046641\n",
    "         s3        s4        s5        s6\n",
    "0 -0.043401 -0.002592  0.019908 -0.017646\n",
    "1  0.074412 -0.039493 -0.068330 -0.092204\n",
    "2 -0.032356 -0.002592  0.002864 -0.025930\n",
    "3 -0.036038  0.034309  0.022692 -0.009362\n",
    "4  0.008142 -0.002592 -0.031991 -0.046641\n",
    "Dataset WITHOUT missing values\n",
    "            age           sex       bmi\n",
    "                                               bp        s1\n",
    "0 -3.634285e-16  5.068012e-02  0.061696  0.021872 -0.044223 -0.034821\n",
    "1 -1.882017e-03 -4.464164e-02 -0.051474 -0.026328 -0.008449 -0.019163\n",
    "2  8.529891e-02  1.308343e-16  0.044451 -0.005671 -0.045599 -0.034194\n",
    "3 -8.906294e-02 -4.464164e-02 -0.011595 -0.036656  0.012191  0.024991\n",
    "4  5.383060e-03 -4.464164e-02 -0.036385  0.021872  0.003935  0.015596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. For machine learning, every dataset does not require normalization. It is required only when features have different ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize dataset\n",
    "from sklearn import preprocessing\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "print(\"This is the dataset after normalisation\")\n",
    "print (pd.DataFrame(normalized_X,columns=diabetes.feature_names).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the dataset after normalisation\n",
    "            age           sex       bmi        bp        s1        s2  \\\n",
    "0 -3.235165e-15  4.511439e-01  0.549207  0.194703 -0.393668 -0.309967\n",
    "1 -1.166166e-02 -2.766158e-01 -0.318952 -0.163137 -0.052351 -0.118743\n",
    "2  7.141360e-01  1.095365e-15  0.372153 -0.047475 -0.381766 -0.286282\n",
    "3 -7.210986e-01 -3.614412e-01 -0.093879 -0.296789  0.098701  0.202336\n",
    "4  6.276940e-02 -5.205457e-01 -0.424265  0.255044  0.045883  0.181859\n",
    "         s3        s4        s5        s6\n",
    "0 -0.386345 -0.023076  0.177221 -0.157082\n",
    "1  0.461081 -0.244715 -0.423396 -0.571330\n",
    "2 -0.270889 -0.021703  0.023976 -0.217093\n",
    "3 -0.291778  0.277782  0.183726 -0.075799\n",
    "4  0.094941 -0.030227 -0.373038 -0.543858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, an outlier is an observation point that is distant from other observations. The above definition suggests that outlier is something which is separate/different from the crowd. We can plot boxplots to get a visual of where the median of the values and the extremes lie, and can observe the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(df['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<matplotlib.axes._subplots.AxesSubplot at 0x23f1ef0cd30>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(df['bmi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<matplotlib.axes._subplots.AxesSubplot at 0x23f1e173fa0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 − Q1. In other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data. It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25) \n",
    "Q3 = df.quantile(0.75) \n",
    "IQR = Q3 - Q1 \n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "age         0.075375\n",
    "sex         0.095322\n",
    "bmi         0.065477\n",
    "bp          0.072300\n",
    "s1 0.062606\n",
    "s2 0.060203\n",
    "s3 0.064429\n",
    "s4 0.073802\n",
    "s5 0.065682\n",
    "s6 0.061096\n",
    "target    124.500000\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       age    sex    bmi     bp     s1     s2     s3     s4     s5     s6  \\\n",
    "0    False  False  False  False  False  False  False  False  False  False\n",
    "1    False  False  False  False  False  False  False  False  False  False\n",
    "2    False  False  False  False  False  False  False  False  False  False\n",
    "3    False  False  False  False  False  False  False  False  False  False\n",
    "4    False  False  False  False  False  False  False  False  False  False\n",
    "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
    "437  False  False  False  False  False  False  False  False  False  False\n",
    "438  False  False  False  False  False  False  False  False  False  False\n",
    "439  False  False  False  False  False  False  False  False  False  False\n",
    "440  False  False  False  False  False  False  False  False  False  False\n",
    "441  False  False  False  False  False  False   True  False  False  False\n",
    "target\n",
    "0 False\n",
    "1 False\n",
    "2 False\n",
    "3 False\n",
    "4 False\n",
    "..      ...\n",
    "437   False\n",
    "438   False\n",
    "439   False\n",
    "440   False\n",
    "441   False\n",
    "[442 rows x 11 columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outlier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Dataframe BEFORE outlier correction\" , df.shape) \n",
    "\n",
    "#Removing Rows with outliers\n",
    "df_outlier_corrected = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).an \n",
    "print(\"Shape of Dataframe AFTER outlier correction\" ,df_outlier_corrected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of Dataframe BEFORE outlier correction (442, 11)\n",
    "Shape of Dataframe AFTER outlier correction (409, 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
